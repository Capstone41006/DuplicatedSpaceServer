{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd0c103-894e-4dff-af52-f4580a6106cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ExifTags\n",
    "from sam2.build_sam import build_sam2_video_predictor\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, db, storage\n",
    "\n",
    "#### 파이어 베이스 설정 ####\n",
    "cred = credentials.Certificate('***')\n",
    "firebase_admin.initialize_app(cred, {\n",
    "    'databaseURL': '***',\n",
    "    'storageBucket': '***'\n",
    "})\n",
    "\n",
    "# use bfloat16 for the entire notebook\n",
    "torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16).__enter__()\n",
    "\n",
    "if torch.cuda.get_device_properties(0).major >= 8:\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    \n",
    "\n",
    "##########################################\n",
    "## Functions                            ##\n",
    "##########################################\n",
    "def show_mask(mask, ax, obj_id=None, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        cmap = plt.get_cmap(\"tab10\")\n",
    "        cmap_idx = 0 if obj_id is None else obj_id\n",
    "        color = np.array([*cmap(cmap_idx)[:3], 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "def get_image_size(image_path):\n",
    "    with Image.open(image_path) as img:\n",
    "        return img.size\n",
    "\n",
    "def get_image_orientation(filepath):\n",
    "    \"\"\"이미지의 EXIF 정보를 읽어 방향을 반환합니다.\"\"\"\n",
    "    image = Image.open(filepath)\n",
    "    orientation = None\n",
    "    try:\n",
    "        exif = image._getexif()\n",
    "        if exif:\n",
    "            for tag, value in exif.items():\n",
    "                if ExifTags.TAGS.get(tag) == 'Orientation':\n",
    "                    orientation = value\n",
    "                    break\n",
    "    except (AttributeError, KeyError, IndexError):\n",
    "        pass\n",
    "    return orientation\n",
    "\n",
    "def process_images_in_folder(input_folder, output_folder, point1, point2):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # 이미지 프레임 이름 목록 가져오기\n",
    "    frame_names = [\n",
    "        p for p in os.listdir(input_folder)\n",
    "        if os.path.splitext(p)[-1] in [\".jpg\", \".jpeg\", \".JPG\", \".JPEG\"]\n",
    "    ]\n",
    "    frame_names.sort(key=lambda p: int(os.path.splitext(p)[0]))\n",
    "\n",
    "    # 초기화\n",
    "    inference_state = predictor.init_state(video_path=input_folder)\n",
    "    predictor.reset_state(inference_state)\n",
    "\n",
    "    # 2. Two Clicks\n",
    "    ann_frame_idx = 0\n",
    "    ann_obj_id = 1\n",
    "\n",
    "    ###### 이미지 비율로 처리 ######\n",
    "    first_frame_path = os.path.join(input_folder, frame_names[0])\n",
    "    image_size = get_image_size(first_frame_path)\n",
    "    point1 = [point1[0] * image_size[0], point1[1]*image_size[1]]\n",
    "    point2 = [point2[0] * image_size[0], point2[1]*image_size[1]]\n",
    "\n",
    "    points = np.array([point1, point2], dtype=np.float32)\n",
    "    labels = np.array([1, 1], np.int32)\n",
    "    _, out_obj_ids, out_mask_logits = predictor.add_new_points_or_box(\n",
    "        inference_state=inference_state,\n",
    "        frame_idx=ann_frame_idx,\n",
    "        obj_id=ann_obj_id,\n",
    "        points=points,\n",
    "        labels=labels,\n",
    "    )\n",
    "\n",
    "    # 비디오 내 모든 프레임에 대해 전파\n",
    "    video_segments = {}\n",
    "    for out_frame_idx, out_obj_ids, out_mask_logits in predictor.propagate_in_video(inference_state):\n",
    "        video_segments[out_frame_idx] = {\n",
    "            out_obj_id: (out_mask_logits[i] > 0.0).cpu().numpy()\n",
    "            for i, out_obj_id in enumerate(out_obj_ids)\n",
    "        }\n",
    "\n",
    "    # 프레임에 대해 시각화 및 마스크 저장\n",
    "    vis_frame_stride = 1\n",
    "    plt.close(\"all\")\n",
    "    for out_frame_idx in range(0, len(frame_names), vis_frame_stride):\n",
    "        if out_frame_idx in video_segments:\n",
    "            frame_path = os.path.join(input_folder, frame_names[out_frame_idx])\n",
    "            frame_image = Image.open(frame_path)\n",
    "            orientation = get_image_orientation(frame_path)\n",
    "            frame_image = np.array(frame_image)\n",
    "            \n",
    "            # plt.figure(figsize=(6, 4))\n",
    "            # plt.title(f\"frame {out_frame_idx}\")\n",
    "            # plt.imshow(frame_image)\n",
    "\n",
    "            masks = []\n",
    "            for out_obj_id, out_mask in video_segments[out_frame_idx].items():\n",
    "                show_mask(out_mask, plt.gca(), obj_id=out_obj_id)\n",
    "                masks.append(out_mask)\n",
    "\n",
    "            save_masks(frame_image, masks, output_folder, frame_names[out_frame_idx], orientation)\n",
    "\n",
    "def save_masks(image, out_masks, output_folder, original_filename, orientation):\n",
    "    # 마스크 처리\n",
    "    black_background = np.zeros_like(image)\n",
    "\n",
    "    # Iterate through each mask and save\n",
    "    for i, out_mask in enumerate(out_masks):\n",
    "        # 마스크의 차원이 3차원인 경우 2차원으로 축소\n",
    "        if len(out_mask.shape) == 3 and out_mask.shape[0] == 1:\n",
    "            out_mask = out_mask.squeeze(0)\n",
    "\n",
    "        # 마스크를 이미지와 동일한 shape로 확장\n",
    "        mask_expanded = out_mask[:, :, np.newaxis]  # (2268, 4032, 1)\n",
    "\n",
    "        # 마스크를 사용하여 이미지와 배경을 결합\n",
    "        masked_image = np.where(mask_expanded, image, black_background)\n",
    "\n",
    "        # PIL 이미지로 변환\n",
    "        masked_image_pil = Image.fromarray(masked_image.astype(np.uint8))\n",
    "\n",
    "        # EXIF 방향 정보를 적용\n",
    "        if orientation:\n",
    "            if orientation == 3:\n",
    "                masked_image_pil = masked_image_pil.rotate(180, expand=True)\n",
    "            elif orientation == 6:\n",
    "                masked_image_pil = masked_image_pil.rotate(270, expand=True)\n",
    "            elif orientation == 8:\n",
    "                masked_image_pil = masked_image_pil.rotate(90, expand=True)\n",
    "\n",
    "        # 파일 이름 수정 및 저장\n",
    "        base_filename, ext = os.path.splitext(original_filename)\n",
    "        output_filename = f\"{base_filename}_masked_{i}.png\"\n",
    "        output_path = os.path.join(output_folder, output_filename)\n",
    "        \n",
    "        masked_image_pil.save(output_path)\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    # 명시적으로 메모리에서 변수 삭제\n",
    "    del sam2_model\n",
    "    del predictor\n",
    "    torch.cuda.empty_cache()  # 캐시된 메모리 해제\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "##########################################\n",
    "## Main Code                            ##\n",
    "##########################################\n",
    "ref_x1 = db.reference('/ref_x1')\n",
    "ref_y1 = db.reference('/ref_y1')\n",
    "ref_x2 = db.reference('/ref_x2')\n",
    "ref_y2 = db.reference('/ref_y2')\n",
    "\n",
    "x1 = ref_x1.get()\n",
    "y1 = ref_y1.get()\n",
    "x2 = ref_x2.get()\n",
    "y2 = ref_y2.get()\n",
    "\n",
    "sam2_checkpoint = \"../checkpoints/sam2_hiera_large.pt\"\n",
    "model_cfg = \"sam2_hiera_l.yaml\"\n",
    "predictor = build_sam2_video_predictor(model_cfg, sam2_checkpoint)\n",
    "\n",
    "input_folder = \"./videos/TEST/input\"\n",
    "output_folder = \"./videos/TEST/output\"\n",
    "point1 = [x1,y1]\n",
    "point2 = [x2,y2]\n",
    "# point1 = [0.7,0.25]\n",
    "# point2 = [0.5,0.25]\n",
    "process_images_in_folder(input_folder, output_folder, point1, point2)\n",
    "print(\"## Backgroun Remove Done ##\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
